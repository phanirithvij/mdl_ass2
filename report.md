## Value Iteration Algorithm

The Bellman equation is the basis of the value iteration algorithm for solving MDPs.

Let `Ut(I)` be the utility value for state s at the t'th iteration. The iteration step, called a Bellman update, looks
like this:


![,,,](https://raw.githubusercontent.com/mallika2011/Machine-Data-Learning/master/A2-2/images/Bellman.png)

Where the Rewards `R(I,A)` for each state is the expected reward of taking action A in State I. That is :

![..](https://github.com/mallika2011/Machine-Data-Learning/blob/master/A2-2/images/Riaj.png?raw=true)

The value iteration algorithm is as follows :

![..](https://github.com/mallika2011/Machine-Data-Learning/blob/master/A2-2/images/vi.png?raw=true)

## Task 1



## Task 2
